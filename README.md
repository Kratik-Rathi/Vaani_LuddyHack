# ğŸ—£ï¸ Vaani â€” Real-Time Audio Intelligence (Luddy Hackathon 2025)

**Vaani** is an advanced real-time audio processing tool built during the **Luddy Hackathon 2025**. It transforms both live and recorded audio into structured, searchable, and intelligent transcripts. From transcription and speaker diarization to summarization and sentiment analysis â€” Vaani makes audio data instantly useful.

---

## ğŸš€ Key Features

- ğŸ™ï¸ **Live & File-based Transcription** using **Fast-Whisper**
- ğŸ§‘â€ğŸ¤â€ğŸ§‘ **Speaker Diarization** using **Distilled-Whisper** and **PyAnnote-Audio**
- ğŸ’¬ **Summarization & Sentiment Analysis** using **Hugging Face Transformers**
- â“ **Question Answering (QnA)** from transcript content
- ğŸ§  Smart chunking for low-latency real-time feedback
- ğŸŒ **Gradio Interface** for seamless interaction

---

## ğŸ“ Project Structure

```
Vaani_LuddyHack/
â”‚
â”œâ”€â”€ app.py                 # Main Gradio interface and orchestrator
â”œâ”€â”€ config.py              # Configuration handling, API key loading, and utility constants
â”œâ”€â”€ live_transcription.py  # Handles real-time audio input and Fast-Whisper transcription
â”œâ”€â”€ summarization.py       # Summarization, sentiment analysis, and QnA using Hugging Face models
â”œâ”€â”€ requirements.txt       # All required packages
â””â”€â”€ .env                   # Stores your secret API keys (ignored in Git)
```

---

## ğŸ”§ Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/Kratik-Rathi/Vaani_LuddyHack.git
cd Vaani_LuddyHack
```

### 2. Create a Virtual Environment

```bash
python -m venv venv
source venv/bin/activate      # On Windows: venv\Scripts\activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Configure API Keys

Create a `.env` file in the root directory with the following content:

```
GROQ_API_KEY=your_groq_api_key_here
HUGGINGFACE_TOKEN=your_huggingface_token_here
```

> ğŸ” You may also need other authentication (e.g., for PyAnnote or WhisperX if using hosted models). Include those as needed.

âš ï¸ **Do not commit your `.env` file**. It contains sensitive keys.

### 5. Launch the App

```bash
python app.py
```

> Gradio will open a local web app in your browser. Start using Vaani immediately!

---

## ğŸ§ª Example Use Cases

- ğŸ“ Transcribing and summarizing lectures or webinars
- ğŸ§‘â€ğŸ’¼ Real-time meeting notes with speaker-wise segmentation
- ğŸ™ï¸ Podcast processing and topic extraction
- ğŸ•µï¸â€â™‚ï¸ Investigative conversation analysis with sentiment breakdown
- ğŸ“Š Generating QnA insights from long audio interviews

---

## ğŸŒ Tech Stack

- ğŸ§  [Fast-Whisper](https://github.com/guillaumekln/faster-whisper) â€” Lightweight Whisper model for fast transcription
- ğŸ§‘â€ğŸ¤â€ğŸ§‘ [WhisperX](https://github.com/m-bain/whisperx) â€” Alignment & Diarization for Whisper
- ğŸ”Š [PyAnnote-Audio](https://github.com/pyannote/pyannote-audio) â€” Speaker diarization from pretrained models
- ğŸ’¬ [Hugging Face Transformers](https://huggingface.co/) â€” For summarization, sentiment, and Q&A
- ğŸŒ [Gradio](https://www.gradio.app/) â€” Fast and interactive frontend
- ğŸ§° PyDub, FFmpeg, Torch â€” Audio preprocessing and model support

---

## ğŸ“œ License

This project is licensed under the [MIT License](LICENSE).

---

## ğŸ™ Acknowledgements

- [Fast-Whisper](https://github.com/guillaumekln/faster-whisper) for efficient transcription
- [WhisperX](https://github.com/m-bain/whisperx) for alignment and diarization
- [PyAnnote](https://github.com/pyannote/pyannote-audio) for speaker diarization
- [Hugging Face](https://huggingface.co/) for state-of-the-art NLP models
- [Gradio](https://www.gradio.app/) for rapid UI development

